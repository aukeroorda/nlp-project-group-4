{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c04a20d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'inseq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minseq\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'inseq'"
     ]
    }
   ],
   "source": [
    "import inseq\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import byt5_model\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed1a3f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd\n",
    "!pip3 install inseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ca9ab-7384-4ade-a3d2-27cca746b4a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform \n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d60eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InseqAttributer:\n",
    "    def __init__(self, model=\"./models/test/\", attribution_method=\"input_x_gradient\") -> None:\n",
    "        \"\"\"Create an object that loads a given model through Inseq with a given attribution method\"\"\"\n",
    "        self.model = inseq.load_model(model, attribution_method)\n",
    "    \n",
    "    def attribute(self, inp:str, out:str=None):\n",
    "        \"\"\"Use the Inseq model to generate feature attributions using a given input or input & output\"\"\"\n",
    "        if inp and out:\n",
    "            inp_out = (inp, out)\n",
    "        else:\n",
    "            inp_out = (inp,)\n",
    "\n",
    "        inseq_out = self.model.attribute(*inp_out,\n",
    "                                         attribute_target=True,\n",
    "                                         step_scores=[\"probability\"]\n",
    "                                        )\n",
    "        inseq_out.show()\n",
    "\n",
    "\n",
    "def predict_on_data(data, model_config_path, spaces=True, device='auto'):\n",
    "    if device == 'auto':\n",
    "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    elif device == 'gpu' or device == 'cuda':\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif device == 'cpu':\n",
    "        device = torch.device(\"cpu\")\n",
    "    else:\n",
    "        print('Set device to auto, cpu, or gpu/cuda.')\n",
    "        return\n",
    "\n",
    "\n",
    "    if spaces:\n",
    "        data['inputs'] = data['lemma'] + ' ' + data['features']\n",
    "    else:\n",
    "        data['inputs'] = data['lemma'] + data['features']\n",
    "\n",
    "\n",
    "    data_gen_comparison = byt5_model.comparer(data, byt5_model.generate(model_config_path, data, device))\n",
    "    data = pd.concat([data, data_gen_comparison], axis=1).rename(columns={'labels': 'plural'})\n",
    "\n",
    "    correct = []\n",
    "    for idx, row in data.iterrows():\n",
    "        if row['Expected'] == row['Predicted']:\n",
    "            correct.append('correct')\n",
    "        else:\n",
    "            correct.append('incorrect')\n",
    "\n",
    "    data = data.assign(correct=correct)\n",
    "\n",
    "    return (data[data.correct == 'incorrect'], data[data.correct == 'correct'])\n",
    "\n",
    "def construct_character_spans(elements):\n",
    "    spans = []\n",
    "    for idx, char in enumerate(elements):\n",
    "        # The capital A with accents denote the start of a two-bytes wide character, for turkish\n",
    "#         These are the characters: ÇĞİÖŞÜçğıöşü\n",
    "        if char.token in 'ÃÄÅ':\n",
    "            spans.append((idx, idx+2))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "\n",
    "def inseq_on_predictions(samples, inseq_model, expected=False):\n",
    "    \n",
    "    count = 0\n",
    "    for idx, sample in samples.iterrows():\n",
    "        count += 1\n",
    "        if count > 1:\n",
    "            print('\\n')\n",
    "        print('='*80)\n",
    "\n",
    "        inp = sample['lemma'] + ' ' + sample['features']\n",
    "        if expected:\n",
    "            print('Testing Expected (gold) outcome (what would the model look at to get to the expected outcome)')\n",
    "            output_type = 'gold'\n",
    "            out = sample['Expected']\n",
    "        else:\n",
    "            print('Testing Predicted (pred) outcome (what did the model take from the input during generation)')\n",
    "            output_type = 'pred'\n",
    "            out = sample['Predicted']\n",
    "\n",
    "        print('Sample: {}\\nIndex: {}\\nThis prediction is {}\\nInput -> output ({}): \\'{}\\' -> \\'{}\\''.format(\n",
    "             count, idx, sample['correct'], output_type, inp, out\n",
    "        ))\n",
    "        if output_type == 'pred':\n",
    "            print(f\"The expected or gold output would be '{sample['Expected']}'\")\n",
    "            contrast = inseq_model.model.encode(sample['Expected'], as_targets=True)\n",
    "\n",
    "\n",
    "        print('='*80)\n",
    "        \n",
    "        # Figure out where the plural suffix is in the word. We only need to attribute from there on out.\n",
    "        plural_suffix_start_index = max([-1] + [out.find(plural_suffix) for plural_suffix in ['ler', 'lar'] if plural_suffix in out])\n",
    "\n",
    "        # If aggregation on the target is disabled, the offset should be not the length of the string, but the byte-length.\n",
    "        # For the attribution start and end, the offset should be compute as byte-length, instead of utf-8 string length\n",
    "#         plural_suffix_start_index = len(out[:plural_suffix_start_index].encode('utf-8'))\n",
    "#         print(f\"{out=}, {plural_suffix_start_index=}\")\n",
    "\n",
    "        # These suffixes are always 3 characters long ('ler' or 'lar')\n",
    "        plural_suffix_end_index = plural_suffix_start_index + 3\n",
    "\n",
    "        if plural_suffix_start_index > 0:  # The suffix is not always present in the output\n",
    "            out = inseq_model.model.attribute(\n",
    "                inp,\n",
    "                out,\n",
    "                show_progress=False,\n",
    "#                 attr_pos_start=plural_suffix_start_index,  # These are unfortunately disabled, as they seem to interfere with the aggregation\n",
    "#                 attr_pos_end=plural_suffix_end_index,    # This causes conflicts with the aggregation.\n",
    "                attribute_target=True,\n",
    "                step_scores=[\"probability\"],\n",
    "            )\n",
    "        else:\n",
    "            out = inseq_model.model.attribute(\n",
    "                inp,\n",
    "                out,\n",
    "                show_progress=False,\n",
    "                attribute_target=True,\n",
    "                step_scores=[\"probability\"],\n",
    "            )\n",
    "        \n",
    "        # Construct source and target spans to aggregate characters that are two bytes wide\n",
    "        source_spans = construct_character_spans(out.sequence_attributions[0].source) or None\n",
    "        target_spans = construct_character_spans(out.sequence_attributions[0].target) or None\n",
    "        print(source_spans, target_spans)\n",
    "        \n",
    "        if source_spans or target_spans:\n",
    "#         if source_spans:\n",
    "            out=inseq.data.aggregator.ContiguousSpanAggregator.aggregate(out.sequence_attributions[0], \n",
    "                                                                    source_spans=source_spans, \n",
    "                                                                    target_spans=target_spans)\n",
    "        out.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d283f0b",
   "metadata": {},
   "source": [
    "## Turkish\n",
    "\n",
    "Focus on relation between last vowel of the stem and the first vowel of the suffix. We expect the last vowel to be salient in predicting the first vowel of the suffix. We focus on plural nouns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320a39c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tur_finetuned = \"./drive-symlink/NLP_project_morphological_inflection/finetuned_tur_3\"\n",
    "inseq_tur_finetuned = InseqAttributer(model_tur_finetuned, \"input_x_gradient\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5542ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_runner(data_sampler('./data/tur.gold', model_tur_finetuned, device='cpu'), inseq_tur_finetuned, expected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f931c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_names = ['lemma', 'labels', 'features']\n",
    "\n",
    "turkish_train = pd.read_csv('./data/tur_large.train', sep='\\t', names=header_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dca2e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "turkish_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7e4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_turkish = turkish_train[\n",
    "    turkish_train['features'].str.startswith('N;')  # Ensure it is a noun\n",
    "  & turkish_train['features'].str.contains('PL;')]  # And plural\n",
    "print(filtered_turkish.size)\n",
    "filtered_turkish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f634eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_turkish, correct_turkish = predict_on_data(filtered_turkish.head(40), model_tur_finetuned)\n",
    "print(f\"Number of incorrect inflections: {len(incorrect_turkish)}, and correct: {len(correct_turkish)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03170a5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "incorrect_attributions = inseq_on_predictions(incorrect_turkish, inseq_tur_finetuned, expected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa11641",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_attributions = inseq_on_predictions(correct_turkish, inseq_tur_finetuned, expected=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32475bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
